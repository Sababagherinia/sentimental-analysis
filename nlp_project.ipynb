{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nlp_project.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sababagherinia/sentimental-analysis/blob/main/nlp_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Kxk9dYj6-mB"
      },
      "source": [
        "#seniment analysis on sentipers dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLGLgqnMTWVs"
      },
      "source": [
        "## installing necessary packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwwWOhsPEzWM",
        "outputId": "6791080d-bde6-4c34-e61c-9d0695d63430"
      },
      "source": [
        "!pip install hazm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: hazm in /usr/local/lib/python3.7/dist-packages (0.7.1)\n",
            "Requirement already satisfied: nltk==3.4 in /usr/local/lib/python3.7/dist-packages (from hazm) (3.4)\n",
            "Requirement already satisfied: libwapiti>=0.2.1; platform_system != \"Windows\" in /usr/local/lib/python3.7/dist-packages (from hazm) (0.2.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk==3.4->hazm) (1.15.0)\n",
            "Requirement already satisfied: singledispatch in /usr/local/lib/python3.7/dist-packages (from nltk==3.4->hazm) (3.6.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVIanxRtj62Q",
        "outputId": "12afcb70-d1d4-4c4b-ad34-3aba83f059fe"
      },
      "source": [
        "! pip install keras"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.4.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras) (1.19.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras) (3.1.0)\n",
            "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py->keras) (1.5.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4NBiBM3hIvTD",
        "outputId": "e46d67f7-dbce-4c55-ac58-d1fcf4ea5da8"
      },
      "source": [
        "!pip install https://github.com/sobhe/hazm/archive/master.zip --upgrade"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting https://github.com/sobhe/hazm/archive/master.zip\n",
            "  Using cached https://github.com/sobhe/hazm/archive/master.zip\n",
            "Requirement already satisfied, skipping upgrade: nltk==3.4 in /usr/local/lib/python3.7/dist-packages (from hazm==0.7.1) (3.4)\n",
            "Requirement already satisfied, skipping upgrade: libwapiti>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from hazm==0.7.1) (0.2.1)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.7/dist-packages (from nltk==3.4->hazm==0.7.1) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: singledispatch in /usr/local/lib/python3.7/dist-packages (from nltk==3.4->hazm==0.7.1) (3.6.2)\n",
            "Building wheels for collected packages: hazm\n",
            "  Building wheel for hazm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hazm: filename=hazm-0.7.1-cp37-none-any.whl size=318809 sha256=7a063a29392f9f9bea70e0e4a2f1035cebcab7fef1a6195229290faa84a03974\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-z7vlq98h/wheels/32/97/cc/640e3b2f3e7b53c5ae336824a31184e86072b8ded31dc0151e\n",
            "Successfully built hazm\n",
            "Installing collected packages: hazm\n",
            "  Found existing installation: hazm 0.7.1\n",
            "    Uninstalling hazm-0.7.1:\n",
            "      Successfully uninstalled hazm-0.7.1\n",
            "Successfully installed hazm-0.7.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAYzTPHZTjqL"
      },
      "source": [
        "## importing general moduels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqmJ7dpkyIJs"
      },
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "import math\n",
        "import numpy as np\n",
        "from hazm import *\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMR5908xTxdP"
      },
      "source": [
        "##loading dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6eL1NClsoRR",
        "outputId": "d6e1a802-ea07-4c0c-cca4-6480f63f0f19"
      },
      "source": [
        "dataset = pd.read_excel('/content/sample_data/sentipers.xlsx')\n",
        "print(dataset.head(10))\n",
        "print(dataset.shape)\n",
        "print(dataset.info())\n",
        "print(dataset.describe())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   index     sid  ... polarity                             file\n",
            "0      0   rev-1  ...        0  data/main/HP LaserJet M1132.xml\n",
            "1      1   rev-2  ...        0  data/main/HP LaserJet M1132.xml\n",
            "2      2   rev-3  ...        0  data/main/HP LaserJet M1132.xml\n",
            "3      3   rev-4  ...        0  data/main/HP LaserJet M1132.xml\n",
            "4      4   rev-5  ...        2  data/main/HP LaserJet M1132.xml\n",
            "5      5   rev-6  ...        0  data/main/HP LaserJet M1132.xml\n",
            "6      6   rev-7  ...        1  data/main/HP LaserJet M1132.xml\n",
            "7      8   rev-9  ...        0  data/main/HP LaserJet M1132.xml\n",
            "8      9  rev-10  ...        1  data/main/HP LaserJet M1132.xml\n",
            "9     10  rev-11  ...        0  data/main/HP LaserJet M1132.xml\n",
            "\n",
            "[10 rows x 5 columns]\n",
            "(15683, 5)\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 15683 entries, 0 to 15682\n",
            "Data columns (total 5 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   index     15683 non-null  int64 \n",
            " 1   sid       15683 non-null  object\n",
            " 2   text      15683 non-null  object\n",
            " 3   polarity  15683 non-null  int64 \n",
            " 4   file      15683 non-null  object\n",
            "dtypes: int64(2), object(3)\n",
            "memory usage: 612.7+ KB\n",
            "None\n",
            "              index      polarity\n",
            "count  15683.000000  15683.000000\n",
            "mean    3816.508321      0.567557\n",
            "std     4428.243825      0.949871\n",
            "min        0.000000     -2.000000\n",
            "25%        8.000000      0.000000\n",
            "50%     1445.000000      1.000000\n",
            "75%     7680.500000      1.000000\n",
            "max    13298.000000      2.000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppyHHLDdT7v7"
      },
      "source": [
        "##preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4D-klbSUAcH"
      },
      "source": [
        "### removing irrelevant coulmns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tU6qzRpozWIK",
        "outputId": "c96be767-c771-4e9b-c2b6-11f329a457e7"
      },
      "source": [
        "dataset = dataset[['text', 'polarity']]\n",
        "print(dataset.head(10))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                text  polarity\n",
            "0  اینک قصد داریم پرینتر دیگری از پرینترهای لیزری...         0\n",
            "1  پرینتری چند کاره از رده‌ی Entry Level یا سطح م...         0\n",
            "2  به هر صورت اکنون ما در دنیایی زندگی می‌کنیم،  ...         0\n",
            "3  به صورتی که توانایی کپی کردن،  اسکن،  فکس،  پر...         0\n",
            "4  به هر صورت معمولا چیزی که بیشتر کاربران از پری...         2\n",
            "5     همچنین عمل اسکن را هم باید خیلی خوب انجام دهد.         0\n",
            "6  M1132 نیز پرینتری است که به نظر یکی از بهترین‌...         1\n",
            "7  همانطور که گفتیم،  M1132 پرینتری لیزری،  تک رن...         0\n",
            "8  ابعاد آن 415 x 265 x 250 میلی متر می‌باشد و وز...         1\n",
            "9  این پرینتر بدنه‌ی مشکی استایلیش و البته نه خیل...         0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cErZ7KXlUNBS"
      },
      "source": [
        "###seperating query and target set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_eawqeCi0Abi",
        "outputId": "97118229-e1cb-4570-d29b-0a9e8ecdedf9"
      },
      "source": [
        "X = dataset.iloc[:, 0]\n",
        "Target = dataset.iloc[:, -1]\n",
        "print(X.head(10))\n",
        "print(X.shape)\n",
        "print(Target.head(10))\n",
        "print(Target.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    اینک قصد داریم پرینتر دیگری از پرینترهای لیزری...\n",
            "1    پرینتری چند کاره از رده‌ی Entry Level یا سطح م...\n",
            "2    به هر صورت اکنون ما در دنیایی زندگی می‌کنیم،  ...\n",
            "3    به صورتی که توانایی کپی کردن،  اسکن،  فکس،  پر...\n",
            "4    به هر صورت معمولا چیزی که بیشتر کاربران از پری...\n",
            "5       همچنین عمل اسکن را هم باید خیلی خوب انجام دهد.\n",
            "6    M1132 نیز پرینتری است که به نظر یکی از بهترین‌...\n",
            "7    همانطور که گفتیم،  M1132 پرینتری لیزری،  تک رن...\n",
            "8    ابعاد آن 415 x 265 x 250 میلی متر می‌باشد و وز...\n",
            "9    این پرینتر بدنه‌ی مشکی استایلیش و البته نه خیل...\n",
            "Name: text, dtype: object\n",
            "(15683,)\n",
            "0    0\n",
            "1    0\n",
            "2    0\n",
            "3    0\n",
            "4    2\n",
            "5    0\n",
            "6    1\n",
            "7    0\n",
            "8    1\n",
            "9    0\n",
            "Name: polarity, dtype: int64\n",
            "(15683,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORPdtOejUa8S"
      },
      "source": [
        "### clearing our texts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFoYOJn7UixX"
      },
      "source": [
        "some actoins like normalizing texts, stemming,removing stop words and lemmatization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3yaS7z_-QaA",
        "outputId": "18c6b04b-a60b-4dda-87fe-eeb0e355a7b5"
      },
      "source": [
        "normalizer = Normalizer()\n",
        "stemmer = Stemmer()\n",
        "lemmatizer = Lemmatizer()\n",
        "def preprocessing(text):\n",
        "    cleared_text = []\n",
        "    text = re.sub('[۰۱۲۳۴۵۶۷۸۹]', '', text)\n",
        "    text = re.sub('[0-9]', '', text)\n",
        "    text = re.sub('[$!?/,.%+*_^():{}\"؟><]', '', text)\n",
        "    text = re.sub(\"-\", '', text)\n",
        "    text = re.sub(\"'\", '', text)\n",
        "    text = normalizer.normalize(text)\n",
        "    text = text.split()\n",
        "    for w in text:\n",
        "          if len(w) > 2:\n",
        "              w = stemmer.stem(w)\n",
        "              w = lemmatizer.lemmatize(w)\n",
        "              cleared_text.append(w)\n",
        "    cleared_text = ' '.join(cleared_text)\n",
        "    return cleared_text\n",
        "clean_docs = []\n",
        "for doc in X.values:\n",
        "    clean_docs.append(preprocessing(doc))\n",
        "print(clean_docs[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "پرینتر چند کاره رده Entry Level سطح مبتد\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EnvSa0xWXN3"
      },
      "source": [
        "###vectorization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s--1tLkJVBQk"
      },
      "source": [
        "####vectorizing text by tf-idf method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6yuLwteGSHDD",
        "outputId": "89bf33c8-79eb-4fc6-eb43-c98f08110319"
      },
      "source": [
        "vectorizer = TfidfVectorizer()\n",
        "X_vector = vectorizer.fit_transform(clean_docs)\n",
        "feature_names = vectorizer.get_feature_names\n",
        "print(X_vector.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(15683, 9214)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSVjKPb9VPB4"
      },
      "source": [
        "####spliting data set to train set and test set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_1gX4oEVY-l"
      },
      "source": [
        "using sklearn split method to split our data by 2 to 8 ratio and 0 random state"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fqs0E45N2goZ",
        "outputId": "d4bcd7ae-5766-4e62-c294-cfa6e923dfe1"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Target_train, Target_test = train_test_split(X_vector, Target, test_size=0.2, random_state=0)\n",
        "print(\"X_train\", X_train.shape)\n",
        "print(\"X_test:\", X_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train (12546, 9214)\n",
            "X_test: (3137, 9214)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "deod5xj6PN5u",
        "outputId": "7d7b2a4b-ded6-4746-d44e-4cff58ed24ff"
      },
      "source": [
        "print(X_vector)\n",
        "print(len(vectorizer.get_feature_names()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  (0, 8826)\t0.15192382756788228\n",
            "  (0, 6674)\t0.31528301569964334\n",
            "  (0, 8815)\t0.29787474645091455\n",
            "  (0, 6206)\t0.40287848167797413\n",
            "  (0, 8299)\t0.3662100190192315\n",
            "  (0, 4612)\t0.22793932868900824\n",
            "  (0, 8297)\t0.31963942996245065\n",
            "  (0, 4224)\t0.1639387396131728\n",
            "  (0, 6043)\t0.3423919382068705\n",
            "  (0, 2561)\t0.44060379546835665\n",
            "  (1, 6280)\t0.34623342793433687\n",
            "  (1, 5090)\t0.2750071092106493\n",
            "  (1, 734)\t0.4615781705879867\n",
            "  (1, 387)\t0.4615781705879867\n",
            "  (1, 4695)\t0.2791110150880839\n",
            "  (1, 8644)\t0.35553141014246564\n",
            "  (1, 8517)\t0.23734555400816648\n",
            "  (1, 8299)\t0.3431417109430171\n",
            "  (2, 4251)\t0.13931095905375118\n",
            "  (2, 4126)\t0.16247081247947787\n",
            "  (2, 4406)\t0.19155614895689255\n",
            "  (2, 4965)\t0.25877078573468126\n",
            "  (2, 9001)\t0.2521256481251571\n",
            "  (2, 5684)\t0.2518023336116107\n",
            "  (2, 2704)\t0.16139416863289016\n",
            "  :\t:\n",
            "  (15681, 4251)\t0.21490309187266077\n",
            "  (15681, 4224)\t0.20356077627743255\n",
            "  (15682, 761)\t0.2169014421393742\n",
            "  (15682, 7746)\t0.24561041819004018\n",
            "  (15682, 7831)\t0.2066257325986272\n",
            "  (15682, 6405)\t0.2078137743573107\n",
            "  (15682, 3777)\t0.1855104431996548\n",
            "  (15682, 6188)\t0.36540150916583425\n",
            "  (15682, 3352)\t0.3209946771145401\n",
            "  (15682, 3109)\t0.1855104431996548\n",
            "  (15682, 5041)\t0.15360548804723473\n",
            "  (15682, 8966)\t0.1806236508876304\n",
            "  (15682, 2063)\t0.23521837978286544\n",
            "  (15682, 2635)\t0.29508251093662285\n",
            "  (15682, 3806)\t0.17597046648588477\n",
            "  (15682, 3184)\t0.15691779601541658\n",
            "  (15682, 3911)\t0.1706287401643285\n",
            "  (15682, 7790)\t0.12978172997494392\n",
            "  (15682, 2125)\t0.19803334558988325\n",
            "  (15682, 3969)\t0.17867747788862764\n",
            "  (15682, 1070)\t0.19716328023667176\n",
            "  (15682, 6186)\t0.2551896392261476\n",
            "  (15682, 1937)\t0.07822303461383306\n",
            "  (15682, 6092)\t0.12808638064672034\n",
            "  (15682, 2521)\t0.0594501805206079\n",
            "9214\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yUkfH03WDDU"
      },
      "source": [
        "converting our sparse matrices to dense matrices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aavskJr0TBEu"
      },
      "source": [
        "X_train_dense = X_train.toarray()\n",
        "X_test_dense = X_test.toarray()\n",
        "# print(X_train.shape)\n",
        "# X_list = X_list.tolist()\n",
        "# X_df = pd.DataFrame(X_train, columns=feature_names)\n",
        "# print(X_df.head(10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9srSKtXNWL1g"
      },
      "source": [
        "##learning Classifiers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9v00Ka3TWsdC"
      },
      "source": [
        "###naive bayes classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7J9Wmj7XW1vv"
      },
      "source": [
        "using sklearn library to learn and predict naive bayes classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMLplbMmTxYj"
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "classifier = GaussianNB()\n",
        "classifier.fit(X_train_dense, Target_train)\n",
        "\n",
        "Target_predict = classifier.predict(X_test_dense)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JG9DvCOsXBql"
      },
      "source": [
        "printing evaluation metrics and confusion matrix for naive bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5U1Fk92ec-NP",
        "outputId": "8c8bd8f3-b0d4-45a6-df7c-61d6939a6ea2"
      },
      "source": [
        "print(classification_report(Target_test, Target_predict))\n",
        "print(confusion_matrix(Target_test, Target_predict))\n",
        "\n",
        "print('accuracy of NB is:', accuracy_score(Target_test, Target_predict))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -2       0.02      0.19      0.04        37\n",
            "          -1       0.15      0.52      0.24       318\n",
            "           0       0.62      0.25      0.36      1182\n",
            "           1       0.42      0.23      0.29      1000\n",
            "           2       0.32      0.37      0.34       600\n",
            "\n",
            "    accuracy                           0.29      3137\n",
            "   macro avg       0.31      0.31      0.25      3137\n",
            "weighted avg       0.44      0.29      0.32      3137\n",
            "\n",
            "[[  7  19   6   4   1]\n",
            " [ 44 165  37  38  34]\n",
            " [116 376 297 190 203]\n",
            " [120 314 101 226 239]\n",
            " [ 58 200  36  84 222]]\n",
            "accuracy of NB is: 0.29231750079693974\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMRuPtncXVsK"
      },
      "source": [
        "###Logistic regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jg3auWEXe5k"
      },
      "source": [
        "using sklearn library to learn and predict logistic regression classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suNK-F9_dbf1"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "classifier = LogisticRegression()\n",
        "classifier.fit(X_train_dense, Target_train)\n",
        "\n",
        "Target_predict = classifier.predict(X_test_dense)\n",
        "\n",
        "print(classification_report(Target_test, Target_predict))\n",
        "print(confusion_matrix(Target_test, Target_predict))\n",
        "print('Accuracy of regression classifier is:', accuracy_score(Target_test, Target_predict))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKDYPTPqXtJm"
      },
      "source": [
        "### Neural Network classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vz6zFMjcZa9T"
      },
      "source": [
        "#### restart the session before fitting NN model again"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocwvxN2rmO67"
      },
      "source": [
        "from keras.backend import clear_session\n",
        "clear_session()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqyWwgU7X2VY"
      },
      "source": [
        "splititg our training set to train and validation set by 25 to 75 ratio and random state 0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9gZfPKEkRLy"
      },
      "source": [
        "X_trainN, X_eval, Target_trainN, Target_eval = train_test_split(X_train_dense, Target_train, test_size=0.25, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KknGjMtnlCUd",
        "outputId": "ce615d93-7313-4e03-95ba-2df38b3b2fec"
      },
      "source": [
        "input_dim = X_trainN.shape[1]\n",
        "print(input_dim)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9214\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y30WMQTdYNjJ"
      },
      "source": [
        "importing keras moduels and creating our network layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ejr3yE_jeL5Q"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "\n",
        "model = Sequential()\n",
        "model.add(layers.Dense(10, input_dim=input_dim, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0dJWSEzYmTT"
      },
      "source": [
        "compiling model and printing a summary of it's structure"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8TeHOQdSlIE_",
        "outputId": "942dc060-7807-419a-b521-cbf61301d758"
      },
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_2 (Dense)              (None, 10)                92150     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 92,161\n",
            "Trainable params: 92,161\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxcZ0mZMYyvd"
      },
      "source": [
        "learning model with training set and validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KJgJQkmmAiy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06eef673-ca9b-4644-960d-f3392ac6412e"
      },
      "source": [
        "model.fit(X_trainN, Target_trainN, epochs=100, verbose=False, validation_data=(X_eval, Target_eval))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa32bf7b710>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAM0SGIVY7V2"
      },
      "source": [
        "evaluate learned model on test set and printing accuarcy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgWejgNomFbj",
        "outputId": "46ea2ca2-31f7-4bce-e807-ef4aad76fa07"
      },
      "source": [
        "loss, accuracy = model.evaluate(X_test_dense, Target_test, verbose=False)\n",
        "print(\"Testing Accuracy: \", accuracy)\n",
        "print(\"Testing Loss: \", loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing Accuracy:  0.48868346214294434\n",
            "Testing Loss:  -242.3919677734375\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4L8l5OeZL4x"
      },
      "source": [
        "####printing confusion matrix and evaluation metrics of NN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIsAlGTAr9A1",
        "outputId": "16a573e2-ab12-4dca-a49c-9c149afda8b6"
      },
      "source": [
        "predicted = model.predict_classes(X_test_dense)\n",
        "print(classification_report(Target_test, predicted))\n",
        "print(confusion_matrix(Target_test, predicted))\n",
        "print('Accuracy of NN classifier is:', accuracy_score(Target_test, predicted))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -2       0.00      0.00      0.00        37\n",
            "          -1       0.00      0.00      0.00       318\n",
            "           0       0.59      0.66      0.62      1182\n",
            "           1       0.42      0.76      0.54      1000\n",
            "           2       0.00      0.00      0.00       600\n",
            "\n",
            "    accuracy                           0.49      3137\n",
            "   macro avg       0.20      0.28      0.23      3137\n",
            "weighted avg       0.35      0.49      0.40      3137\n",
            "\n",
            "[[  0   0  27  10   0]\n",
            " [  0   0 244  74   0]\n",
            " [  0   0 777 405   0]\n",
            " [  0   0 244 756   0]\n",
            " [  0   0  33 567   0]]\n",
            "Accuracy of NN classifier is: 0.48868345553076187\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}